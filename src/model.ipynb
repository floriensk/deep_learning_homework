{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning homework\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/floriensk/deep_learning_homework/blob/main/src/model.ipynb\">\n",
    "<button>\n",
    "Open in Colab\n",
    "</button>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install requests\n",
    "# %pip install tqdm\n",
    "# %pip install sklearn"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data fetching\n",
    "We use the *fairface* dataset to train our model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use a streaming solution to fetch data, this way we are able to track progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import requests\n",
    "import os\n",
    "\n",
    "def download_file(uri, target_path):\n",
    "    # Create directory path to target file\n",
    "    if not os.path.exists(os.path.dirname(target_path)):\n",
    "        os.makedirs(os.path.dirname(target_path))\n",
    "\n",
    "    # Download file using streaming, so we can iterate over the response\n",
    "    response = requests.get(uri, stream=True)\n",
    "    total_size_in_bytes= int(response.headers.get('content-length', 0)) # Get the total size of data to download\n",
    "    block_size = 1024 # Download in chunks for progress tracking\n",
    "    progress_bar = tqdm(total=total_size_in_bytes, unit='iB', unit_scale=True) # Use a progress bar to track progress\n",
    "\n",
    "    with open(target_path, 'wb') as file:\n",
    "        for data in response.iter_content(block_size):\n",
    "            progress_bar.update(len(data))\n",
    "            file.write(data) # Write downloaded chunk to file\n",
    "    progress_bar.close()\n",
    "\n",
    "    if total_size_in_bytes != 0 and progress_bar.n != total_size_in_bytes:\n",
    "        print(f\"Error during download of {target_path}\")\n",
    "    else:\n",
    "        print(f\"Downloading {target_path} finished successfully\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading the images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we fetch the images from the corresponding Google Drive folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = \"../data\" # Path of directory to extract the downloaded data into\n",
    "\n",
    "dir_original_train_valid_path = os.path.join(dir_path, \"train\")\n",
    "dir_original_test_path = os.path.join(dir_path, \"val\")\n",
    "\n",
    "dir_train_valid_path = os.path.join(dir_path, \"train_valid\")\n",
    "dir_test_path = os.path.join(dir_path, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shutil import rmtree\n",
    "\n",
    "def remove_directory(path):\n",
    "    rmtree(path, ignore_errors=True)\n",
    "\n",
    "def rename_dataset_directories():\n",
    "    # Turn \"train\" into \"train_valid\"\n",
    "    if os.path.exists(dir_original_train_valid_path):\n",
    "        remove_directory(dir_train_valid_path)\n",
    "        os.rename(dir_original_train_valid_path, dir_train_valid_path)\n",
    "\n",
    "    # Turn \"val\" into \"test\"\n",
    "    if os.path.exists(dir_original_test_path):\n",
    "        remove_directory(dir_test_path)\n",
    "        os.rename(os.path.join(dir_path, \"val\"), dir_test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_VALID_IMAGES_COUNT = 86744 # Number of images in the training and validation set in the fairface dataset\n",
    "TEST_IMAGES_COUNT = 10954 # Number of images in the test set in the fairface dataset\n",
    "\n",
    "rename_dataset_directories()\n",
    "\n",
    "DOWNLOAD_DATASET = (not os.path.exists(dir_train_valid_path)\n",
    "    or len(os.listdir(dir_train_valid_path)) != TRAIN_VALID_IMAGES_COUNT\n",
    "    or not os.path.exists(dir_test_path)\n",
    "    or len(os.listdir(dir_test_path)) != TEST_IMAGES_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_file_path = \"../data/fairface.zip\" # Path of downloaded ZIP file\n",
    "\n",
    "if DOWNLOAD_DATASET:\n",
    "    # Remove old directories (if they exist)\n",
    "    remove_directory(dir_train_valid_path)\n",
    "    remove_directory(dir_test_path)\n",
    "\n",
    "    # Download dataset ZIP file\n",
    "    uri_images = \"https://drive.google.com/uc?export=download&id=1g7qNOZz9wC7OfOhcPqH1EZ5bk1UFGmlL&confirm=t&uuid=729c215d-4fa4-4799-b03f-aea00a016230&at=ALAFpqx7EciTPuBT0YNhhbYsVpML:1666561770553\"\n",
    "\n",
    "    download_file(uri_images, images_file_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uncompressing the images"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The images need to be uncompressed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DOWNLOAD_DATASET:\n",
    "    from zipfile import ZipFile\n",
    "\n",
    "    with ZipFile(images_file_path) as zip:\n",
    "        zip.extractall(dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete ZIP after extracting\n",
    "try:\n",
    "    os.remove(images_file_path)\n",
    "except OSError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_dataset_directories()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading the labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we fetch the CSV files containing the labels for the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_train_valid_file_path = os.path.join(dir_path, \"labels_train_valid.csv\") # Will be split into train and valid, so already naming it that way\n",
    "\n",
    "labels_test_file_path = os.path.join(dir_path, \"labels_test.csv\") # Will be used as test set, so already naming it that way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(labels_train_valid_file_path):\n",
    "    uri_labels_train = \"https://drive.google.com/uc?export=download&id=1i1L3Yqwaio7YSOCj7ftgk8ZZchPG7dmH\"\n",
    "    download_file(uri_labels_train, labels_train_valid_file_path) # Download train and valid data sets\n",
    "\n",
    "if not os.path.exists(labels_test_file_path):\n",
    "    uri_labels_val = \"https://drive.google.com/uc?export=download&id=1wOdja-ezstMEp81tX1a-EYkFebev4h7D\"\n",
    "    download_file(uri_labels_val, labels_test_file_path) # Download test data set"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, read the labels into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "labels_train_valid = np.loadtxt(labels_train_valid_file_path, delimiter=\",\", skiprows=1, dtype=\"str\") # Read while skipping header\n",
    "labels_test = np.loadtxt(labels_test_file_path, delimiter=\",\", skiprows=1, dtype=\"str\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data segmentation\n",
    "Finally, we split the data into train, validation and test datasets for further use by our model.\n",
    "\n",
    "Data in the downloaded dataset is already split into *train* and *val* subsets (the latter makes up about 10% of all images). Since we need to split the dataset into train, validation and test subsets, we will turn the specified *val* subset into the test subset and split the specified *train* subset into train and validation subsets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rename the extracted folders accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "import tensorflow\n",
    "from tensorflow.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Extracts the file name from a file path\n",
    "def get_file_name(file_path):\n",
    "    split_path = tensorflow.strings.split(file_path, \"\\\\\").numpy()\n",
    "    split_path = np.atleast_2d(split_path)[:,-1]\n",
    "    split_path = tensorflow.strings.split(split_path, \"/\").numpy()\n",
    "    split_path = np.atleast_2d(split_path)[:,-1]\n",
    "    \n",
    "    return split_path\n",
    "\n",
    "## Returns the image as a numpy array from a file path\n",
    "def get_image(file_path):\n",
    "    return tensorflow.keras.utils.img_to_array(\n",
    "        tensorflow.keras.utils.load_img(file_path)\n",
    "    )\n",
    "\n",
    "## Returns the labels for a file path\n",
    "## @param test_dataset: if True, the test dataset will be used, otherwise the train and valid dataset\n",
    "def get_labels(file_path, test_dataset=False):\n",
    "    file_name = get_file_name(file_path) # get only the file name, without a path\n",
    "\n",
    "    labels = labels_test if test_dataset else labels_train_valid # get the desired set of labels\n",
    "    \n",
    "    return labels[get_file_name(labels[:, 0]) == file_name].ravel()[1:] # get the labels for the file name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We one-hot encode all labels separately, then construct the desired output of the model by concatenating these arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encode labels\n",
    "labels_all = np.append(labels_train_valid, labels_test, axis=0)\n",
    "\n",
    "age_encoder = preprocessing.OneHotEncoder(sparse=False, dtype=\"float32\")\n",
    "age_encoder.fit(labels_all[:, 1].reshape(-1, 1))\n",
    "\n",
    "gender_encoder = preprocessing.OneHotEncoder(sparse=False, dtype=\"float32\")\n",
    "gender_encoder.fit(labels_all[:, 2].reshape(-1, 1))\n",
    "\n",
    "race_encoder = preprocessing.OneHotEncoder(sparse=False, dtype=\"float32\")\n",
    "race_encoder.fit(labels_all[:, 3].reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AGE_KEY = \"age\"\n",
    "GENDER_KEY = \"gender\"\n",
    "RACE_KEY = \"race\"\n",
    "\n",
    "## Converts the labels to the output of the model\n",
    "def encode_labels(labels):\n",
    "    labels = np.atleast_2d(labels)\n",
    "\n",
    "    age_labels = age_encoder.transform(np.atleast_2d(labels[:, 0]).astype(str))\n",
    "    gender_labels = gender_encoder.transform(np.atleast_2d(labels[:, 1]).astype(str))\n",
    "    race_labels = race_encoder.transform(np.atleast_2d(labels[:, 2]).astype(str))\n",
    "    \n",
    "    # create an array of one-hot encoded labels for the multiple outputs\n",
    "    # return np.array([age_labels.ravel(),\n",
    "    #         gender_labels.ravel(),\n",
    "    #         race_labels.ravel()], dtype=object)\n",
    "    # return (age_labels.ravel(),\n",
    "            # gender_labels.ravel(),\n",
    "            # race_labels.ravel())\n",
    "    return {\n",
    "        AGE_KEY: age_labels.ravel(),\n",
    "        GENDER_KEY: gender_labels.ravel()[:1],\n",
    "        RACE_KEY: race_labels.ravel()\n",
    "    }\n",
    "\n",
    "## Converts the output of the model to the decoded labels\n",
    "def decode_labels(labels):\n",
    "    age_labels = age_encoder.inverse_transform(np.atleast_2d(labels[0]))\n",
    "    gender_labels = gender_encoder.inverse_transform(np.atleast_2d(labels[1]))\n",
    "    race_labels = race_encoder.inverse_transform(np.atleast_2d(labels[2]))\n",
    "\n",
    "    return np.append( # append the decoded labels\n",
    "        np.append(\n",
    "            age_labels,\n",
    "            gender_labels,\n",
    "            axis=1\n",
    "        ),\n",
    "        race_labels,\n",
    "        axis=1\n",
    "    ).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_datapoint(file_names_and_labels, files_directory_path):\n",
    "    for file_name, *labels in file_names_and_labels:\n",
    "        file_name = get_file_name(file_name)[0]\n",
    "        # file_name = file_name.decode('utf-8')\n",
    "        file_path = os.path.join(files_directory_path, file_name)\n",
    "        \n",
    "        yield (\n",
    "            get_image(file_path),\n",
    "            encode_labels(labels)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train_valid = Dataset.from_generator(\n",
    "    generate_datapoint,\n",
    "    args=(labels_train_valid, dir_train_valid_path),\n",
    "    output_signature=(\n",
    "        tensorflow.TensorSpec(shape=(None, None, 3), dtype=tensorflow.float32),\n",
    "        {\n",
    "            AGE_KEY: tensorflow.TensorSpec(shape=(None,), dtype=tensorflow.float32),\n",
    "            GENDER_KEY: tensorflow.TensorSpec(shape=(None,), dtype=tensorflow.float32),\n",
    "            RACE_KEY: tensorflow.TensorSpec(shape=(None,), dtype=tensorflow.float32)\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # output_types=(tensorflow.float32, tensorflow.float32),\n",
    "    # output_shapes=(\n",
    "    #     tensorflow.TensorShape([None, None, 3]),\n",
    "    #     {\n",
    "    #         OUTPUT_AGE_KEY: tensorflow.TensorShape([None]),\n",
    "    #         OUTPUT_GENDER_KEY: tensorflow.TensorShape([None]),\n",
    "    #         OUTPUT_RACE_KEY: tensorflow.TensorShape([None])\n",
    "    #     }\n",
    "    # )\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the first data set into train and validation data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_ratio = 0.8\n",
    "batch_size = 64\n",
    "\n",
    "data_count_train = int(len(labels_train_valid) * train_data_ratio)\n",
    "data_count_valid = len(labels_train_valid) - data_count_train\n",
    "data_count_test = len(labels_test)\n",
    "\n",
    "# split the dataset into train and validation data\n",
    "dataset_train = dataset_train_valid.take(data_count_train, name=\"dataset_train\")\n",
    "dataset_valid = dataset_train_valid.skip(data_count_train, name=\"dataset_valid\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, prepare the datasets to be an appropriate source for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(dataset):\n",
    "    return (dataset\n",
    "        .repeat()\n",
    "        .batch(\n",
    "            batch_size,\n",
    "            num_parallel_calls=tensorflow.data.experimental.AUTOTUNE,\n",
    "            deterministic=False,\n",
    "            name=\"dataset_batch\"\n",
    "        ).prefetch(tensorflow.data.experimental.AUTOTUNE, name=\"dataset_prefetch\"))\n",
    "\n",
    "\n",
    "dataset_train = prepare_dataset(dataset_train)\n",
    "dataset_valid = prepare_dataset(dataset_valid)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have successfully created the three subsets, *train*, *valid* and *test*. (Note that in the file system, only test is in a separate directory, as it was that way in the original database. Separating the other subsets would be an unnecessary operation.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_count = data_count_train + data_count_valid + data_count_test\n",
    "\n",
    "print(f\"train: {data_count_train:,} images ({data_count_train / images_count * 100:.1f}%)\".replace(\",\", \" \")) # replace the ',' thousands separator with ' '\n",
    "print(f\"valid: {data_count_valid:,} images ({data_count_valid / images_count * 100:.1f}%)\".replace(\",\", \" \"))\n",
    "print(f\"test:  {data_count_test :,} images ({data_count_test  / images_count * 100:.1f}%)\".replace(\",\", \" \"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below can demonstrate that the data is correctly provided to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image, labels = dataset_train.as_numpy_iterator().next()\n",
    "\n",
    "# decoded_labels = decode_labels(labels[0])\n",
    "\n",
    "# from matplotlib import pyplot as plt\n",
    "\n",
    "# plt.imshow(image[0] / 255.)\n",
    "# plt.title(f\"{decoded_labels}\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model, Input\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D, GlobalAveragePooling2D, Rescaling\n",
    "# from tensorflow.keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a model based on the VGG16 architecture, which became unstable for reasons we could not find out. We thus discontinued using the model below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_shape = images_train.shape[1:]\n",
    "# kernel_size = (3, 3)\n",
    "# convolution_activation = None\n",
    "# convolution_padding = \"same\"\n",
    "# kernel_counts = [32, 64, 128, 128, 128]\n",
    "\n",
    "# base_model = Sequential()\n",
    "# base_model.add(Conv2D(kernel_counts[0], kernel_size, input_shape=image_shape, padding=convolution_padding, activation=convolution_activation))\n",
    "# base_model.add(Conv2D(kernel_counts[0], kernel_size, padding=convolution_padding))\n",
    "# base_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# base_model.add(Conv2D(kernel_counts[1], kernel_size, padding=convolution_padding, activation=convolution_activation))\n",
    "# base_model.add(Conv2D(kernel_counts[1], kernel_size, padding=convolution_padding))\n",
    "# base_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# base_model.add(Conv2D(kernel_counts[2], kernel_size, padding=convolution_padding, activation=convolution_activation))\n",
    "# base_model.add(Conv2D(kernel_counts[2], kernel_size, padding=convolution_padding))\n",
    "# base_model.add(Conv2D(kernel_counts[2], kernel_size, padding=convolution_padding))\n",
    "# base_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# base_model.add(Conv2D(kernel_counts[3], kernel_size, padding=convolution_padding, activation=convolution_activation))\n",
    "# base_model.add(Conv2D(kernel_counts[3], kernel_size, padding=convolution_padding))\n",
    "# base_model.add(Conv2D(kernel_counts[3], kernel_size, padding=convolution_padding))\n",
    "# base_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# base_model.add(Conv2D(kernel_counts[4], kernel_size, padding=convolution_padding, activation=convolution_activation))\n",
    "# base_model.add(Conv2D(kernel_counts[4], kernel_size, padding=convolution_padding))\n",
    "# base_model.add(Conv2D(kernel_counts[4], kernel_size, padding=convolution_padding))\n",
    "# base_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# base_model.add(Flatten())\n",
    "# base_model.add(Dense(1000, activation=\"relu\"))\n",
    "# base_model.add(Dropout(0.5))\n",
    "# base_model.add(Dense(500, activation=\"relu\"))\n",
    "# base_model.add(Dropout(0.5))\n",
    "# base_model.add(Dense(labels_train.shape[1], activation=\"softmax\"))\n",
    "\n",
    "# base_model.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We decided on using the original VGG16 model, with which, however, we couldn't train on our dataset either."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final data preprocessing (normalisation) is done in the model itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = dataset_train_valid.as_numpy_iterator().next()[0].shape\n",
    "\n",
    "def build_model():\n",
    "    # use VGG16 as base model for transfer learning\n",
    "    base_model = VGG16(\n",
    "        include_top=False,\n",
    "        input_shape=input_shape,\n",
    "        input_tensor=Input(shape=input_shape),\n",
    "    )\n",
    "    base_model.trainable = False # freeze the base model\n",
    "\n",
    "    # Create a separate model for the appended layers, so that the trainable property can be set separately\n",
    "    appended_model_base = Sequential(name=\"appended_model\")\n",
    "    appended_model_base.add(GlobalAveragePooling2D(input_shape=base_model.output_shape[1:]))\n",
    "    appended_model_base.add(Dense(512, activation=\"swish\"))\n",
    "    appended_model_base.add(Dropout(0.2))\n",
    "    appended_model_base.add(Dense(100, activation=\"swish\"))\n",
    "    appended_model_base.add(Dropout(0.2))\n",
    "\n",
    "\n",
    "    # appended_model = Model(appended_model_base.input, [output_age, output_gender, output_race], name=\"appended_model\")\n",
    "\n",
    "    # Connect the base and appended models\n",
    "    inputs = Input(shape=input_shape, name=\"main_model_input\")\n",
    "    model_functional = preprocess_input(inputs)\n",
    "    model_functional = base_model(model_functional, training=False)\n",
    "    model_functional = appended_model_base(model_functional)\n",
    "    # Branch for the 3 output layers corresponding to the 3 different labels\n",
    "    output_age    = Dense(9, activation=\"softmax\", name=AGE_KEY)   (model_functional)\n",
    "    output_gender = Dense(1, activation=\"sigmoid\", name=GENDER_KEY)(model_functional)\n",
    "    output_race   = Dense(7, activation=\"softmax\", name=RACE_KEY)  (model_functional)\n",
    "\n",
    "    return Model(inputs, [output_age, output_gender, output_race], name=\"main_model\")\n",
    "\n",
    "model = build_model()\n",
    "\n",
    "model.compile(loss=[\"categorical_crossentropy\", \"binary_crossentropy\", \"categorical_crossentropy\"], optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We tried various batch sizes, optimizers, number of attached final dense layers with various sizes and activations, but our accuracy would barely exceed 0.06 even on the training data set. We were unable to tell why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 2\n",
    "\n",
    "model.fit(\n",
    "    dataset_train,\n",
    "    epochs=epochs,\n",
    "    validation_data=dataset_valid,\n",
    "    steps_per_epoch=data_count_train // batch_size,\n",
    "    validation_steps=data_count_valid // batch_size,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As our model did not learn as expected, evaluating its performance became obsolete. If we, however, figured out how the training process could avoid failing (which we definitely will!), we would add the following to our notebook:\n",
    "1. Load the test data set into memory and preprocess it similarly to the train and validation data sets.\n",
    "1. Execute our model on the test data set to see its final performance.\n",
    "1. Compute the confusion matrix of our model for all parameters, age, gender and race to see its performance broken down by each individual parameter.\n",
    "\n",
    "Then we would further experiment with how transfer learning could be done efficiently, as a final goal of our project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions for interpreting the output of the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_age(model_output):\n",
    "    model_output = np.atleast_2d(model_output)\n",
    "    return age_encoder.inverse_transform(model_output[:, :age_encoder.categories_[0].shape[0]]).reshape(-1)\n",
    "\n",
    "def get_gender(model_output):\n",
    "    model_output = np.atleast_2d(model_output)\n",
    "    return gender_encoder.inverse_transform(model_output[:, age_encoder.categories_[0].shape[0]:][:,gender_encoder.categories_[0].shape[0]]).reshape(-1)\n",
    "\n",
    "def get_race(model_output):\n",
    "    model_output = np.atleast_2d(model_output)\n",
    "    return race_encoder.inverse_transform(model_output[:, -race_encoder.categories_[0].shape[0]:]).reshape(-1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dc1c9eb218cc5e25e848c84021af89099061b305f10f96c210bebd3d437c2ee0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
