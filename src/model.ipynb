{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning homework\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/floriensk/deep_learning_homework/blob/main/src/data.ipynb\">\n",
    "<button>\n",
    "Open in Colab\n",
    "</button>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install requests\n",
    "%pip install tqdm\n",
    "%pip install sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data fetching\n",
    "We use the *fairface* dataset to train our model.\n",
    "\n",
    "We use a streaming solution to fetch data, this way we are able to track progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import requests\n",
    "import os\n",
    "\n",
    "def download_file(uri, target_path):\n",
    "    # Create directory path to target file\n",
    "    if not os.path.exists(os.path.dirname(target_path)):\n",
    "        os.makedirs(os.path.dirname(target_path))\n",
    "\n",
    "    # Download file using streaming, so we can iterate over the response\n",
    "    response = requests.get(uri, stream=True)\n",
    "    total_size_in_bytes= int(response.headers.get('content-length', 0)) # Total size of data to download\n",
    "    block_size = 1024 # Download in chunks for progress tracking\n",
    "    progress_bar = tqdm(total=total_size_in_bytes, unit='iB', unit_scale=True) # Use a progress bar to track progress\n",
    "\n",
    "    with open(target_path, 'wb') as file:\n",
    "        for data in response.iter_content(block_size):\n",
    "            progress_bar.update(len(data))\n",
    "            file.write(data) # Write downloaded chunk to file\n",
    "    progress_bar.close()\n",
    "\n",
    "    if total_size_in_bytes != 0 and progress_bar.n != total_size_in_bytes:\n",
    "        print(f\"Error during download of {target_path}\")\n",
    "    else:\n",
    "        print(f\"Downloading {target_path} finished successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we fetch the images from the corresponding Google Drive folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = \"../data\" # Path of directory to extract the downloaded data into"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uri_images = \"https://drive.google.com/uc?export=download&id=1g7qNOZz9wC7OfOhcPqH1EZ5bk1UFGmlL&confirm=t&uuid=729c215d-4fa4-4799-b03f-aea00a016230&at=ALAFpqx7EciTPuBT0YNhhbYsVpML:1666561770553\"\n",
    "images_file_path = \"../data/fairface.zip\" # Path of downloaded ZIP file\n",
    "\n",
    "download_file(uri_images, images_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we fetch the CSV files containing the labels for the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "uri_labels_train = \"https://drive.google.com/uc?export=download&id=1i1L3Yqwaio7YSOCj7ftgk8ZZchPG7dmH\"\n",
    "labels_train_valid_file_path = os.path.join(dir_path, \"labels_train_valid.csv\") # Will be split into train and valid, so already naming it that way\n",
    "\n",
    "uri_labels_val = \"https://drive.google.com/uc?export=download&id=1wOdja-ezstMEp81tX1a-EYkFebev4h7D\"\n",
    "labels_test_file_path = os.path.join(dir_path, \"labels_test.csv\") # Will be used as test set, so already naming it that way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_file(uri_labels_train, labels_train_valid_file_path) # Download train and valid data sets\n",
    "download_file(uri_labels_val, labels_test_file_path) # Download test data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data extraction\n",
    "The data needs to be uncompressed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "\n",
    "with ZipFile(images_file_path) as zip:\n",
    "    zip.extractall(dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete ZIP after extracting\n",
    "os.remove(images_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we read the labels into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "labels_train_valid = np.loadtxt(labels_train_valid_file_path, delimiter=\",\", skiprows=1, dtype=\"str\") # Read while skipping header\n",
    "labels_test = np.loadtxt(labels_test_file_path, delimiter=\",\", skiprows=1, dtype=\"str\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data segmentation\n",
    "Finally, we split the data into train, validation and test datasets for further use by our model.\n",
    "\n",
    "Data in the downloaded dataset is already split into *train* and *val* subsets (the latter makes up about 10% of all images). Since we need to split the dataset into train, validation and test subsets, we will turn the specified *val* subset into the test subset and split the specified *train* subset into train and validation subsets.\n",
    "\n",
    "The resulting split ratios are as follows:\n",
    "+ train: ~74%\n",
    "+ validation: ~15%\n",
    "+ test: ~11%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_train_valid_path = os.path.join(dir_path, \"train_valid\")\n",
    "dir_test_path = os.path.join(dir_path, \"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rename the extracted folders accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn \"train\" into \"train_valid\"\n",
    "os.rename(os.path.join(dir_path, \"train\"), dir_train_valid_path)\n",
    "# Turn \"val\" into \"test\"\n",
    "os.rename(os.path.join(dir_path, \"val\"), dir_test_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have successfully created the three subsets, *train*, *valid* and *test*. (Note that in the file system, only test is in a separate directory, as it was in the original database that way. Separating the other subsets would be an unnecessary operation.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 72089 images (73.8%)\n",
      "valid: 14655 images (15.0%)\n",
      "test:  10954 images (11.2%)\n"
     ]
    }
   ],
   "source": [
    "# train_images_count = len(labels_train)\n",
    "# valid_images_count = len(labels_valid)\n",
    "# test_images_count = len(labels_test)\n",
    "# images_count = train_images_count + valid_images_count + test_images_count\n",
    "\n",
    "# print(f\"train: {train_images_count} images ({train_images_count / images_count * 100:.1f}%)\")\n",
    "# print(f\"valid: {valid_images_count} images ({valid_images_count / images_count * 100:.1f}%)\")\n",
    "# print(f\"test:  {test_images_count} images ({test_images_count / images_count * 100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from sklearn import preprocessing\n",
    "import tensorflow\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initially, we wanted to use a generator to feed data into the network, but the popular generator API provided by keras seemed to be incompatible with our goal to classify according to multiple labels at the same time. However, loading all data into memory has limitations due to limited memory, so until we further improve our model, we only use a subset of the train data, 10 000 samples.\n",
    "\n",
    "For the same reason, we do not load the test data set into memory yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_count = 10000\n",
    "\n",
    "labels_train_valid = labels_train_valid[:train_data_count]\n",
    "\n",
    "images_train_valid = [\n",
    "    keras.utils.img_to_array(keras.utils.load_img(os.path.join(dir_train_valid_path, file[0].split(\"/\")[1]))) # read the file name from the labels and load the image\n",
    "    for file in labels_train_valid]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess the input according to the needs of the VGG16 model. This involves scaling pixel values to [0; 1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "images_train_valid = np.array(images_train_valid)\n",
    "images_train_valid = preprocess_input(images_train_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We one-hot encode all labels separately, then construct the desired output of the model by concatenating these arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encode labels\n",
    "age_encoder = preprocessing.OneHotEncoder(sparse=False)\n",
    "age_labels = age_encoder.fit_transform(labels_train_valid[:, 1].reshape(-1, 1))\n",
    "\n",
    "gender_encoder = preprocessing.OneHotEncoder(sparse=False)\n",
    "gender_labels = gender_encoder.fit_transform(labels_train_valid[:, 2].reshape(-1, 1))\n",
    "\n",
    "race_encoder = preprocessing.OneHotEncoder(sparse=False)\n",
    "race_labels = race_encoder.fit_transform(labels_train_valid[:, 3].reshape(-1, 1))\n",
    "\n",
    "labels_train_valid_encoded = np.append(age_labels, gender_labels, axis=1)\n",
    "labels_train_valid_encoded = np.append(labels_train_valid_encoded, race_labels, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, split the first data set into train and validation data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train and valid\n",
    "images_train, images_valid, labels_train, labels_valid = train_test_split(images_train_valid, labels_train_valid_encoded, test_size=0.2, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "\n",
    "# from tensorflow.keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a model based on the VGG16 architecture, which became unstable for reasons we could not find out. We thus discontinued using the model below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_shape = images_train.shape[1:]\n",
    "# kernel_size = (3, 3)\n",
    "# convolution_activation = None\n",
    "# convolution_padding = \"same\"\n",
    "# kernel_counts = [32, 64, 128, 128, 128]\n",
    "\n",
    "# base_model = Sequential()\n",
    "# base_model.add(Conv2D(kernel_counts[0], kernel_size, input_shape=image_shape, padding=convolution_padding, activation=convolution_activation))\n",
    "# base_model.add(Conv2D(kernel_counts[0], kernel_size, padding=convolution_padding))\n",
    "# base_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# base_model.add(Conv2D(kernel_counts[1], kernel_size, padding=convolution_padding, activation=convolution_activation))\n",
    "# base_model.add(Conv2D(kernel_counts[1], kernel_size, padding=convolution_padding))\n",
    "# base_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# base_model.add(Conv2D(kernel_counts[2], kernel_size, padding=convolution_padding, activation=convolution_activation))\n",
    "# base_model.add(Conv2D(kernel_counts[2], kernel_size, padding=convolution_padding))\n",
    "# base_model.add(Conv2D(kernel_counts[2], kernel_size, padding=convolution_padding))\n",
    "# base_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# base_model.add(Conv2D(kernel_counts[3], kernel_size, padding=convolution_padding, activation=convolution_activation))\n",
    "# base_model.add(Conv2D(kernel_counts[3], kernel_size, padding=convolution_padding))\n",
    "# base_model.add(Conv2D(kernel_counts[3], kernel_size, padding=convolution_padding))\n",
    "# base_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# base_model.add(Conv2D(kernel_counts[4], kernel_size, padding=convolution_padding, activation=convolution_activation))\n",
    "# base_model.add(Conv2D(kernel_counts[4], kernel_size, padding=convolution_padding))\n",
    "# base_model.add(Conv2D(kernel_counts[4], kernel_size, padding=convolution_padding))\n",
    "# base_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# base_model.add(Flatten())\n",
    "# base_model.add(Dense(1000, activation=\"relu\"))\n",
    "# base_model.add(Dropout(0.5))\n",
    "# base_model.add(Dense(500, activation=\"relu\"))\n",
    "# base_model.add(Dropout(0.5))\n",
    "# base_model.add(Dense(labels_train.shape[1], activation=\"softmax\"))\n",
    "\n",
    "# base_model.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We decided on using the original VGG16 model, with which, however, we couldn't train on our dataset either."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg16 import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_shape = images_train.shape[1:]\n",
    "\n",
    "base_model = VGG16(include_top=False, input_shape=image_shape) # use VGG16 as base model for transfer learning\n",
    "\n",
    "base_model.trainable = False # freeze the base model\n",
    "\n",
    "# Create new model on top\n",
    "inputs = keras.Input(shape=image_shape)\n",
    "x = base_model(inputs, training=False)\n",
    "\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(100, activation=\"relu\")(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(labels_train.shape[1], activation=\"softmax\")(x)\n",
    "\n",
    "model = keras.Model(inputs, x)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " vgg16 (Functional)          (None, 7, 7, 512)         14714688  \n",
      "                                                                 \n",
      " global_average_pooling2d_1   (None, 512)              0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 100)               51300     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 100)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 18)                1818      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,767,806\n",
      "Trainable params: 53,118\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We tried various batch sizes, optimizers, number of attached final dense layers with various sizes and activations, but our accuracy would barely exceed 0.06 even on the training data set. We were unable to tell why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "267/267 [==============================] - 1151s 4s/step - loss: 371.6778 - accuracy: 0.0569 - val_loss: 594.9734 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "267/267 [==============================] - 1223s 5s/step - loss: 1625.4622 - accuracy: 0.0571 - val_loss: 1575.1426 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "267/267 [==============================] - 1167s 4s/step - loss: 2977.4841 - accuracy: 0.0558 - val_loss: 2755.6418 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n"
     ]
    }
   ],
   "source": [
    "batch_size = 30\n",
    "epochs = 10\n",
    "\n",
    "model.fit(\n",
    "    images_train,\n",
    "    labels_train,\n",
    "    epochs=epochs,\n",
    "    validation_data=(images_valid, labels_valid),\n",
    "    batch_size=batch_size,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As our model did not learn as expected, evaluating its performance became obsolete. If we, however, figured out how the training process could avoid failing (which we definitely will!), we would add the following to our notebook:\n",
    "1. Load the test data set into memory and preprocess it similarly to the train and validation data sets.\n",
    "1. Execute our model on the test data set to see its final performance.\n",
    "1. Compute the confusion matrix of our model for all parameters, age, gender and race to see its performance broken down by each individual parameter.\n",
    "\n",
    "Then we would further experiment with how transfer learning could be done efficiently, as a final goal of our project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions for interpreting the output of the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_age(model_output):\n",
    "    model_output = np.atleast_2d(model_output)\n",
    "    return age_encoder.inverse_transform(model_output[:, :age_encoder.categories_[0].shape[0]]).reshape(-1)\n",
    "\n",
    "def get_gender(model_output):\n",
    "    model_output = np.atleast_2d(model_output)\n",
    "    return gender_encoder.inverse_transform(model_output[:, age_encoder.categories_[0].shape[0]:][:,gender_encoder.categories_[0].shape[0]]).reshape(-1)\n",
    "\n",
    "def get_race(model_output):\n",
    "    model_output = np.atleast_2d(model_output)\n",
    "    return race_encoder.inverse_transform(model_output[:, -race_encoder.categories_[0].shape[0]:]).reshape(-1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dc1c9eb218cc5e25e848c84021af89099061b305f10f96c210bebd3d437c2ee0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
